{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie Konkursowe: Rozpoznawanie tweet'ów\n",
    "\n",
    "Zadaniem jest analiza wiadomości zamieszczanych w serwisie Twitter i okreslanie czy opisują one katastrofę/wypadek. Biorąc pod uwagę wszechobecność telefonów komórkowych, umozliwiającą publikowanie wiadomości na mediach społecznościowych z dowolnego miejsca i praktycznie natychmiastowo, wyszukiwanie tweet'ów opisujących wypadki może pokóc w zbieraniu informacji i szybkiego reagowania na sytuacje kryzysowe.\n",
    "\n",
    "## Dane\n",
    "Plik `train.csv` zawiera zbiór wiadomości z mediów społecznościowych, wraz ze ewentualnymi danymi takimi jak lokacja czy uzyte słowa kluczowe (nie dla każdej z wiadomości), a także kolumnę \"target\". Wartość 0 w tej kolumnie oznacza że wiadomość nie opisuje katastrofy, 1 oznacza katastrofę/wypadek.\n",
    "\n",
    "Plik `test.csv` zawiera podobny zestaw wiadomości bez kolumny target i służy do sprawdzenia działania algorytmu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "090d5ea1-7e56-4757-8222-2ebde65691a6",
    "_uuid": "497dffb8-44d9-40e6-a059-7ddc07b4c1c2"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "\n",
    "#odczytanie plików csv z setami\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oczyszczanie wiadomości\n",
    "Wiadomości odczytane z kolumny \"text\" pliku `train.csv` muszą zostać odpowiednio przetworzone przed wykorzystaniem ich do trenowania modelu. \n",
    "\n",
    "Funkcja `process_text(text)` przyjmuje ciąg znaków.\n",
    "```\n",
    "noPunc = [char for char in text if char not in string.punctuation]\n",
    "noPunc = ''.join(noPunc)\n",
    "```\n",
    "Powyższy kod usuwa znaki interpunkcyjne z wiadomości po czym ponownie skleja wiadomość.\n",
    "```\n",
    "STOPWORDS = stopwords.words('english')\n",
    "' '.join([word for word in noPunc.split() if word.lower() not in STOPWORDS])\n",
    "```\n",
    "Powyższy kod usuwa z tekstu \"śmieciowe\" (w tym kontekście) słowa, takie jak spójniki i zaimki, które na pewno nie decydują o tym czy wiadomość opisuje wypadek, a mogłyby być brane pod uwagę przez model.\n",
    "\n",
    "Korzystając z funkcji `.apply(process_text)` poddajemy każdą wiadomość działaniu funkcji `process_text(text)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0          Deeds Reason earthquake May ALLAH Forgive us       1  \n",
      "1                 Forest fire near La Ronge Sask Canada       1  \n",
      "2     residents asked shelter place notified officer...       1  \n",
      "3     13000 people receive wildfires evacuation orde...       1  \n",
      "4     got sent photo Ruby Alaska smoke wildfires pou...       1  \n",
      "...                                                 ...     ...  \n",
      "7608  Two giant cranes holding bridge collapse nearb...       1  \n",
      "7609  ariaahrary TheTawniest control wild fires Cali...       1  \n",
      "7610  M194 0104 UTC5km Volcano Hawaii httptcozDtoyd8EbJ       1  \n",
      "7611  Police investigating ebike collided car Little...       1  \n",
      "7612  Latest Homes Razed Northern California Wildfir...       1  \n",
      "\n",
      "[7613 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    #przyjmuje ciąg znaków, usuwa znaki interpunkcyjne, spójniki i inne \"śmieciowe\" słowa\n",
    "    STOPWORDS = stopwords.words('english')\n",
    "    \n",
    "    #wydziela wszystkie znaki które nie są interpunkcją\n",
    "    noPunc = [char for char in text if char not in string.punctuation]\n",
    "    #łączy z powrotem w wiadomość\n",
    "    noPunc = ''.join(noPunc)\n",
    "    #usuwa angielskie spójniki itd.\n",
    "    return ' '.join([word for word in noPunc.split() if word.lower() not in STOPWORDS])\n",
    "\n",
    "train_df.text=train_df.text.apply(process_text)\n",
    "test_df.text=test_df.text.apply(process_text)\n",
    "\n",
    "#train_df.describe()\n",
    "\n",
    "print(pd.DataFrame(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Do zadania wybrano grupę modeli określanych jako [Naiwne Klasyfikatory Bayesowskie](https://scikit-learn.org/stable/modules/naive_bayes.html). Ich nazwa pochodzi z \"naiwnego\" założenie leżącego u ich podstaw: wszystkie zmienne na podstawie których dokonywane jest przewidywanie są niezależne. Choć jest to ogromne uproszczenie, to często klasyfikatory te działają dość dobrze, a w przypadku tego zadania same poszczególne słowa, bez uzwględniania kontekstu pomiędzy nimi, mogą okazać się wystarczająco dobrym wskaźnikiem. Testując kilka typów tych klasyfikatorów, najlepsze rezultaty osiągnięto dla wariantu klasyfikatora Bernoulli Naive Bayes.\n",
    "\n",
    "`count_vectorizer = feature_extraction.text.CountVectorizer()` jest narzędziem które na podstawie całego zbioru wiadomości tworzy funkcję, gdzie każde występujące słowa ma przypisaną pozycję w wektorze. Wynikiem tej funkcji dla każdej wiadomości jest wektor gdzie na pozycjach słów które występują w tej wiadomości pojawiają się jedynki, a na pozostałych zera.\n",
    "\n",
    "```\n",
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])\n",
    "```\n",
    "Powyższy kod tworzy dokonuje wektoryzacji dla danych treningowych i testowych. Ponieważ operacji \"fit\" (definiującej funkcję) dokonano tylko dla danych treningowych, dla danych testowych korzystamy z tej samej funkcji (co jest konieczne aby model działał w ten sam sposób dla obu zestawów)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64850427 0.63636364 0.73955296]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB, ComplementNB\n",
    "\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "nb = BernoulliNB()\n",
    "\n",
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "nb.fit(train_vectors, train_df[\"target\"])\n",
    "\n",
    "scores = model_selection.cross_val_score(nb, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyniki\n",
    "Model osiągnął skuteczność 73,9% dla danych treningowych, natomiast działając na danych testowych, wygenerowane wyniki sprawdziły się dla 79,2% wiadomości.\n",
    "![](wyniki.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"target\"] = nb.predict(test_vectors)\n",
    "\n",
    "sample_submission.head()\n",
    "\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
